# Report for HW2 Mini-LIMA of CS2916

TODO: This markdown file need to be transfered into a latex file.

## Division of labor

Youwei Zhong, 521030910084,  John Class: Instruction data construction, its README and its report
Jie Wei, xxxxxxxxxxxx, ACM Class: Aligning via supervised fine-tuning, its README and its report
Ruohong Jiang, xxxxxxxxxxxx, ACM Class: Model performance evaluation, its README and its report

## Instruction data construction

Instruction data construction is divided into three phases: seed task expansion, instance generation and adjustments. We generate 75 more seed tasks (with at least an instance) based on the original 175 tasks and generate at least 4 instances other than the original instance for each expanded seed task. The format is aligned with the original json file.

### Seed task expansion

The core code is as follows:

```python
while len(seed_tasks) < 250:
    selected_tasks = random.sample(seed_tasks, 8)
    prompt = (
        'Generate a new seed task based on the following instructions and include an example instance. Be sure to keep the format as:\n{"name": "...", "instruction": "...", "instances": [{"input": "...", "output": "..."}], "is_classification": ...}\n'
        + "\n".join([task["instruction"] for task in selected_tasks])
    )

    new_task_description = generate_new_task(prompt)
    ...
```

In each step, the program choose 8 random seed tasks and give it to GPT-3.5-Turbo using the prompt above. Note that in this `seed_tasks` include both original and new ones, unlike Self-instruct, which use 6 original ones and 2 new ones. In this way, we hope that the generated seed tasks will not strongly affected by the seed tasks that are generated in the first several steps.

### Instance generation

The core code is as follows:

```python
for task in seed_tasks:
	i = 0
	while len(task["instances"]) < 5:
		new_instances = generate_instances(task, max(0, 5 - len(task["instances"])))
		if new_instances:
			task["instances"].extend(new_instances)
		i += 1
		if i > 10:
			failed_tasks.append(task)
			print(f"Failed to generate new instances for task {task['id']}.")
			break

	new_tasks.append(task)
```

The while loop is meant for possible wrong format that calls for regeneration.

We category the instructions into 3 classes: classification task, non-classification task with input, non-classification task without input. The prompt for the three classes is as follows:

Classification task:

```python
prompt = f"Here is a classification task named \"{task['name']}\", the instruction of the classification task is:\n{task['instruction']}\nFor example, when the input is:\n{task['instances'][0]['input']}\nthe output is:\n{task['instances'][0]['output']}\nGenerate {n} new pairs of input and output, be sure to keep the format the same as [{{\"input\": \"the content of new input\", \"output\": \"the content of new output\"}}, ...]\nTry to balance the number of different classes in the {n} new pairs."
```

Non-classification task with input:

```python
prompt = f"Here is a task named \"{task['name']}\", the instruction of the task is:\n{task['instruction']}\nFor example, when the input is:\n{task['instances'][0]['input']}\nthe output is:\n{task['instances'][0]['output']}\nGenerate {n} new pairs of input and output, be sure to keep the format the same as [{{\"input\": \"the content of new input\", \"output\": \"the content of new output\"}}, ...]"
```

Non-classification task without input:

```python
prompt = f"Here is a task named \"{task['name']}\", the instruction of the task is:\n{task['instruction']}\nFor example, the output is:\n{task['instances'][0]['output']}\nGenerate {n} new pairs of input and output, since this is a task that doesn't have an input, be sure to keep the format the same as [{{\"input\": \"\", \"output\": \"the content of new output\"}}, ...], where the input should be an empty string and the output should be a non-empty string."
```

The instance generation process uses GPT-3.5-Turbo.

### Adjustments

After generation, we check the generated seed tasks and their instances (not the original seed tasks, given limited time) manually one by one, and regenerate the ones that are obviously wrong using GPT-4 manually. We notice that this manually checking phase can be replaced by LLM and scripts as done in Self-instruct. We don't implement this phase for simplicity and higher quality.

Here is an example of wrong seed task that we categorize as "not generating code" generated by GPT-3.5-Turbo:
```json
{"id": "seed_task_226", "name": "Write a JavaScript Script for Current Date and Time", "instruction": "Write a JavaScript script to display the current date and time.", "instances": [{"input": "", "output": "console.log(`Current Date and Time: ${new Date().toLocaleString()}`);"}, {"input": "", "output": "Current Date and Time: 10/07/2022, 11:30:45 AM"}, {"input": "", "output": "Current Date and Time: 12/15/2022, 03:20:10 PM"}, {"input": "", "output": "Current Date and Time: 06/28/2023, 09:45:30 AM"}, {"input": "", "output": "Current Date and Time: 11/09/2023, 01:15:55 PM"}], "is_classification": false}
```

We use this prompt: "Fix the instruction by actually writing code and combining all words to one line:" in these wrong cases of "not generating code". The GPT-4 outputs the following result:

```json
{"id":"seed_task_226","name":"Write a JavaScript Script for Current Date and Time","instruction":"Write a JavaScript script that, when executed, prints the current date and time in the console using the `toLocaleString` method.","instances":[{"input":"","output":"console.log(`Current Date and Time: ${new Date().toLocaleString()}`);"},{"input":"","output":"console.log(`Current Date and Time: ${new Date().toLocaleString()}`);"},{"input":"","output":"console.log(`Current Date and Time: ${new Date().toLocaleString()}`);"},{"input":"","output":"console.log(`Current Date and Time: ${new Date().toLocaleString()}`);"},{"input":"","output":"console.log(`Current Date and Time: ${new Date().toLocaleString()}`);"}],"is_classification":false}
```

The following is another wrong example generated by GPT-3-Turbo:

```json
{"id": "seed_task_229", "name": "Write a haiku with the word 'breeze'", "instruction": "Write a haiku (a traditional Japanese poem) using the word 'breeze'. A haiku consists of three lines with a syllable pattern of 5-7-5.", "instances": [{"input": "Whispers through the trees, caressing with gentle ease, nature's soothing breeze.", "output": "Whispers through the trees, caressing with gentle ease, nature's soothing breeze."}, {"input": "Summer breeze carries, whispers of a distant shore, peace in every breath.", "output": "Summer breeze carries, whispers of a distant shore, peace in every breath."}, {"input": "Moonlight dances free, under the starlit sky's tease, a gentle night breeze.", "output": "Moonlight dances free, under the starlit sky's tease, a gentle night breeze."}, {"input": "Autumn leaves that please, rustling softly in the trees, a cool, crisp breeze.", "output": "Autumn leaves that please, rustling softly in the trees, a cool, crisp breeze."}, {"input": "Sails glide on the seas, carried by the salt-kissed breeze, freedom in the winds.", "output": "Sails glide on the seas, carried by the salt-kissed breeze, freedom in the winds."}], "is_classification": false}
```

Using this prompt: "Fix the instruction by changing the literary form and the key word, keeping the input as an empty string, only writing in the output and combining all words to one line:", GPT-4 outputs the following result:

```json
{"id":"seed_task_229","name":"Write a Limerick with the Word 'Moon'","instruction":"Write a limerick (a humorous, often nonsensical poem) using the word 'moon'. A limerick consists of five lines with a rhyme scheme AABBA.","instances":[{"input":"","output":"There once was a man from the dunes, who'd sing to the stars and the moon. He'd dance in the sand, with a drink in his hand, and wouldn't come home until noon."},{"input":"","output":"A cat with a soft silvery spoon, made wishes each night to the moon. Her dreams filled with mice, and everything nice, yet she slept all the morning and noon."},{"input":"","output":"A wizard who lived on a moon, stirred potions with a long wooden spoon. He mixed up a brew, that turned skies from gray to blue, and laughed as he hummed a tune."},{"input":"","output":"A town where the people are loons, all dream under the light of the moon. They howl and they cheer, without any fear, and sleep every day until noon."},{"input":"","output":"In a village where flowers bloom soon, the nights are all lit by the moon. They dance and they play, in a magical way, and sadness is gone all too soon."}],"is_classification":false}
```

Some tasks generate very short passages (just a short message) so I try to extend the message a bit longer. For instance, the following is a task to choose the correct passage:

```python
{"id": "seed_task_234", "name": "Identify Answer Passage", "instruction": "Determine which passage from the provided list contains the answer to the given query. Output the index of the correct passage.", "instances": [{"input": {"query": "What is the capital of France?", "passages": ["Passage 1: Paris is known for its cafes.", "Passage 2: The capital of France is Paris.", "Passage 3: France is in Europe."]}, "output": "Passage 2"}, {"input": {"query": "Who is the author of 'Romeo and Juliet'?", "passages": ["Passage 1: Shakespeare wrote many plays.", "Passage 2: 'Romeo and Juliet' is a story of love.", "Passage 3: The author of 'Romeo and Juliet' is William Shakespeare."]}, "output": "Passage 3"}, {"input": {"query": "What is the largest planet in our solar system?", "passages": ["Passage 1: Earth is the third planet from the sun.", "Passage 2: Jupiter is the largest planet in our solar system.", "Passage 3: Mars is often called the red planet."]}, "output": 1}, {"input": {"query": "Who wrote the famous play 'Romeo and Juliet'?", "passages": ["Passage 1: Shakespeare wrote 'Hamlet'.", "Passage 2: 'Romeo and Juliet' was written by William Shakespeare.", "Passage 3: Jane Austen wrote 'Pride and Prejudice'."]}, "output": 2}, {"input": {"query": "What is the highest mountain in the world?", "passages": ["Passage 1: Mount Kilimanjaro is the highest mountain in Africa.", "Passage 2: Mount Everest is the tallest mountain in the world.", "Passage 3: The Alps are a famous mountain range in Europe."]}, "output": 2}], "is_classification": false}
```

Using this prompt: "Fix the instances by actually giving complete and long passages instead  of only one sentence and combining all words to one line:", GPT-4 outputs the following result:

```python
{"id":"seed_task_234","name":"Identify Answer Passage","instruction":"Determine which passage from the provided list contains the answer to the given query. Output the index of the correct passage.","instances":[{"input":{"query":"What is the capital of France?","passages":["Passage 1: Paris, the city of lights, is known globally for its art, fashion, gastronomy, and culture. While it offers numerous iconic cafes, it is also the political and economic heart of France.","Passage 2: The capital of France is Paris, which has been an important city for more than 2,000 years. On the River Seine in northern France, it is known for its culture, beauty, and vibrant history that dates back to the Roman times.","Passage 3: France is located in Europe. It is bordered by six countries: Belgium and Luxembourg to the northeast, Germany and Switzerland to the east, Italy and Monaco to the southeast, and Spain to the south."]},"output":"2"},{"input":{"query":"Who is the author of 'Romeo and Juliet'?","passages":["Passage 1: Shakespeare, a prominent English playwright of the 16th century, wrote many plays during his lifetime, including tragedies, comedies, and historical pieces that are still celebrated today for their profound influence on English literature.","Passage 2: 'Romeo and Juliet' is a tragic story of love and conflict that transcends family feuds in Verona, Italy. The play explores themes of passion, fate, and the inevitability of death, painting a poignant portrait of star-crossed lovers.","Passage 3: The author of 'Romeo and Juliet' is William Shakespeare, an iconic figure in English literature, whose works have transcended time and genre to remain relevant and revered in educational curricula worldwide."]},"output":"3"},{"input":{"query":"What is the largest planet in our solar system?","passages":["Passage 1: Earth, our home planet, is the third from the sun and unique in its ability to support life. Known for its diverse ecosystems and climates, Earth is one of the smaller planets in our solar system.","Passage 2: Jupiter, the largest planet in our solar system, has a mass one-thousandth that of the sun but is two and a half times the mass of all the other planets combined. It is predominantly composed of hydrogen and helium.","Passage 3: Mars, often called the red planet, is famous for its iron oxide-rich soil which gives it a reddish appearance. This fourth planet from the sun has been the focus of numerous robotic exploration missions."]},"output":"2"},{"input":{"query":"Who wrote the famous play 'Romeo and Juliet'?","passages":["Passage 1: Shakespeare, the renowned playwright from Stratford-upon-Avon, wrote many significant plays, including 'Hamlet', which delve deep into human psychology and complex relationships.","Passage 2: 'Romeo and Juliet', a profound exploration of young love and family conflict, was penned by William Shakespeare, marking it as one of his most renowned works, often adapted into various forms including films, musicals, and ballets.","Passage 3: Jane Austen, an English novelist known for her keen observations on the societal roles of the 19th century, wrote several novels like 'Pride and Prejudice' that explore issues of morality, upbringing, and marriage in the landed gentry of Britain."]},"output":"2"},{"input":{"query":"What is the highest mountain in the world?","passages":["Passage 1: Mount Kilimanjaro, located in Tanzania, is the highest mountain in Africa, rising approximately 19,341 feet above sea level. It is a dormant volcano with three volcanic cones.","Passage 2: Mount Everest, at an elevation of 29,032 feet, is the highest mountain in the world. Situated in the Mahalangur Himal sub-range of the Himalayas, the mountain spans the border between Nepal and the Tibet Autonomous Region of China.","Passage 3: The Alps, stretching approximately 1,200 kilometers across eight Alpine countries, are one of Europe's major mountain ranges and a popular destination for tourists seeking skiing, hiking, and mountaineering."]},"output":"2"}],"is_classification":true}
```

